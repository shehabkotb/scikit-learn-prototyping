{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pre\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy of Replacing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_STRATEGY_MEAN = \"mean\"\n",
    "REPLACE_STRATEGY_MEDIAN = \"median\"\n",
    "REPLACE_STRATEGY_MOST_FREQUENT = \"most_frequent\"\n",
    "\n",
    "# Replace missing values with specific constant\n",
    "# which passed to fill_value parameter\n",
    "REPLACE_STRATEGY_CONSTANT = \"constant\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy of Dropping Missing Values\n",
    "**DROP_IF_ANY_NA** -> Drop the row/column if any of the values is null. <br>\n",
    "**DROP_IF_ALL_NA** -> Drop the row/column if all the values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_IF_ANY_NA = 'any'\n",
    "DROP_IF_ALL_NA = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, data):\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "**Feature scaling** is a method used to normalize the range of independent variables or features of data.\n",
    "Since the range of values of raw data varies widely, in some data mining algorithms, objective functions will not work properly without normalization. For example, many classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Scaler\n",
    "Transform features by scaling each feature to a given range. <br>\n",
    "This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one. <br>\n",
    "The transformation is given by: <br> <br>\n",
    "**X_std = (X - X.min(axis=axis)) / (X.max(axis=axis) - X.min(axis=axis))** <br>\n",
    "**X_scaled = X_std * (feature_range.max - feature_range.min) + feature_range.min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxScale(self, feature_range=(0, 1), axis=0):\n",
    "    self.data = pre.minmax_scale(self.data, feature_range=feature_range, axis=axis)\n",
    "    return self\n",
    "Preprocessing.minMaxScale = minMaxScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Scaler\n",
    "This scaler is calculated by formula <br>\n",
    "**X_scaled = X / X.max(axis=axis)** <br>\n",
    "All entries in result matrix is less than or equal to 1 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxScale(self, axis=0):\n",
    "    self.data = pre.maxabs_scale(self.data, axis=axis)\n",
    "    return self\n",
    "Preprocessing.maxScale = maxScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Scaler\n",
    "This scaler is calculated by formula <br>\n",
    "**X_scaled = X / X.min(axis=axis)** <br>\n",
    "All entries in result matrix is greater than or equal to 1 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minScale(self, axis=0):\n",
    "    if (axis != 0):\n",
    "        for r in range(self.data.shape[0]):\n",
    "            self.data[r, :] = self.data[r, :] / self.data[r, :].min()\n",
    "        return self\n",
    "    \n",
    "    for c in range(self.data.shape[1]):\n",
    "        self.data[:, c] = self.data[:, c] / self.data[:, c].min()\n",
    "    return self\n",
    "Preprocessing.minScale = minScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler\n",
    "Standardize features by removing the mean and scaling to unit variance <br>\n",
    "The standard score of a sample x is calculated as: <br>\n",
    "\n",
    "**z = (x - u) / s**\n",
    "\n",
    "where **u** is the mean of the training samples or zero if **with_mean=False**, and s is the standard deviation of the training samples or one if **with_std=False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardScale(self, with_mean=True, with_std=True):\n",
    "    stdScaler = pre.StandardScaler(with_mean=with_mean, with_std=with_std)\n",
    "    self.data = stdScaler.fit(self.data).transform(self.data)\n",
    "    return self\n",
    "Preprocessing.standardScale = standardScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "**Encoding** is the process of converting categorical features into numberical features\n",
    "- **categorical_axis**: index of axis of the categorical feature \n",
    "- **axis**: if 0 -> categorical axis is a column, else categorical axis is row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(self, categorical_axis, axis=0):\n",
    "    if axis == 0:\n",
    "        le = pre.LabelEncoder().fit(self.data[:,categorical_axis])\n",
    "        self.data[:, categorical_axis] = le.transform(self.data[:, categorical_axis])\n",
    "    else:\n",
    "        le = pre.LabelEncoder().fit(self.data[categorical_axis, :])\n",
    "        self.data[categorical_axis, :] = le.transform(self.data[categorical_axis, :])\n",
    "    return self\n",
    "Preprocessing.encode = encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converts data-type of entries inside data matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(self, dtype):\n",
    "    self.data = np.asarray(self.data, dtype=dtype)\n",
    "    return self\n",
    "Preprocessing.convert = convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Missings\n",
    "**DropMissings** function is used to remove rows and columns with **Null/NaN** values.\n",
    "- **axis**: possible values are {0 or ‘index’, 1 or ‘columns’}, default 0. If 0, drop rows with null values. If 1, drop columns with missing values.\n",
    "- **how**: possible values are {‘any’, ‘all’}, default ‘any’. If ‘any’, drop the row/column if any of the values is null. If ‘all’, drop the row/column if all the values are missing.\n",
    "- **thresh**: an int value to specify the threshold for the drop operation.\n",
    "- **subset**: specifies the rows/columns to look for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropMissings(self, axis=0, how=DROP_IF_ANY_NA, thresh=None, subset=None):\n",
    "    df = pd.DataFrame(self.data)\n",
    "    df.dropna(axis=axis, how=how, thresh=thresh, subset=subset, inplace=True)\n",
    "    self.data = df.to_numpy()\n",
    "    return self\n",
    "Preprocessing.dropMissings = dropMissings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Missings\n",
    "**ReplaceMissings** function is used to remove rows with **Null/NaN** values.\n",
    "- **missing_values**: The placeholder for the missing values. All occurrences of missing_values will be imputed.\n",
    "- **strategy**: The imputation strategy.\n",
    "- **fill_value**: When strategy == REPLACE_STRATEGY_CONSTANT, fill_value is used to replace all occurrences of missing_values. If left to the default, fill_value will be 0 when imputing numerical data and “missing_value” for strings or object data types.\n",
    "- **axis**: if axis==0 -> feature values in columns else feature values in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceMissings(self, missing_values=np.nan, strategy=REPLACE_STRATEGY_MEAN, fill_value=0, axis=0):\n",
    "    if (axis != 0):\n",
    "        self.data = self.data.transpose()\n",
    "    imp_mean = SimpleImputer(missing_values=missing_values,strategy=strategy, fill_value=fill_value)\n",
    "    self.data = imp_mean.fit_transform(self.data)\n",
    "    if (axis != 0):\n",
    "        self.data = self.data.transpose()\n",
    "    return self\n",
    "Preprocessing.replaceMissings = replaceMissings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Result\n",
    "Returns the result matrix as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(self):\n",
    "    return self.data\n",
    "Preprocessing.getResult = getResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([\n",
    "    [1, 2, 3, 'C1'],\n",
    "    [3, None, 5, 'C2'],\n",
    "    [6, 7, np.nan, 'C3'],\n",
    "    [6, 7, 5, 'C2'],\n",
    "    [6, 7, 5, 'C3']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 0.],\n",
       "       [6., 7., 5., 1.],\n",
       "       [6., 7., 5., 2.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocessing(arr).encode(3).convert(np.float64).dropMissings().getResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([\n",
    "    [1, 2, 3, 'C1'],\n",
    "    [3, None, 5, 'C2'],\n",
    "    [6, 7, np.nan, 'C3'],\n",
    "    [6, 7, 5, 'C2'],\n",
    "    [6, 7, 5, 'C3']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 0.],\n",
       "       [3., 3., 5., 1.],\n",
       "       [6., 7., 5., 2.],\n",
       "       [6., 7., 5., 1.],\n",
       "       [6., 7., 5., 2.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = Preprocessing(arr2).encode(3).convert(np.float64).replaceMissings(axis=1).getResult()\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[:, 3] = arr[:, 3] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        ],\n",
       "       [3.        , 1.5       , 1.66666667, 2.        ],\n",
       "       [6.        , 3.5       , 1.66666667, 3.        ],\n",
       "       [6.        , 3.5       , 1.66666667, 2.        ],\n",
       "       [6.        , 3.5       , 1.66666667, 3.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocessing(arr2).minScale(axis=0).getResult()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
